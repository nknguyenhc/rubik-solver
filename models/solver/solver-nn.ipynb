{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d27fa5-7d96-4cfa-b9c7-a50686a62185",
   "metadata": {},
   "source": [
    "As attempted in [solver.ipynb](solver.ipynb), informed search can perform relatively well. I must say, this is quite an achievement after CS2040S and CS2109S. However, it takes forever to solve some configurations. Hence, in this notebook, I will be attempting a neural network solution at finding the shortest solution to Rubik's cube."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5618c413-fcad-44e5-8e09-93c0abcf6a19",
   "metadata": {},
   "source": [
    "## Rubik's cube convention\n",
    "\n",
    "To recap, Rubik's cube has the following index convention:\n",
    "\n",
    "![Rubik indices](images/face-indices.png)\n",
    "\n",
    "Given a state in numpy array of dimension 6 x 3 x 3, the index corresponds to the face indicated above. The central face in the image is the front face.\n",
    "Each block is then a 3 x 3 array that corresponds to the cells.\n",
    "\n",
    "Each cell colour is indicated by an integer between 0 to 5 (inclusive).\n",
    "\n",
    "The correspondences between indices and faces are:\n",
    "* 0: face up (U)\n",
    "* 1: face left (L)\n",
    "* 2: face front (F)\n",
    "* 3: face right (R)\n",
    "* 4: face down (D)\n",
    "* 5: face back (B)\n",
    "\n",
    "Each action is one of `\"L\"`, `\"L'\"`, `\"R\"`, `\"R'\"`, `\"F\"`, `\"F'\"`, `\"B\"`, `\"B'\"`, `\"U\"`, `\"U'\"`, `\"D\"`, `\"D'\"`, where action without apostrophe `'` is clockwise and action with apostrophe `'` is anticlockwise. Clockwise direction is determined by the rotation of the face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27861cf4-6e43-4e68-b274-cadd5742b9af",
   "metadata": {},
   "source": [
    "## Neural network\n",
    "\n",
    "The neural network is designed as such: given a Rubik's cube position, return the best move for that position. Hence the neural network will take 54 inputs, and return 12 outputs. The 54 inputs represents the cube position, while the 12 outputs represents the normalized probabilities of the 12 possible moves.\n",
    "\n",
    "We will be reusing the informed search algorithm, for data generation. For each cube position, we do an informed search to find a solution. If the solution is not found within the time limit, we take the first step from the model solution. Otherwise, we take the first step from the more efficient solution, between the one given by informed search and the model solution.\n",
    "\n",
    "The informed search we would use to generate inputs would be:\n",
    "\n",
    "* Hashmap\n",
    "* Heuristic: uniformity - coeff * steps_taken\n",
    "* Coefficient: 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dbb54c0-f005-4f54-ada1-c0fd5d084953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries for this notebook\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from sortedcontainers import SortedSet\n",
    "\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b6865b3-470a-43bd-aa69-3c2f74bb3659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the utils\n",
    "\n",
    "class Rubik:\n",
    "    actions = [\"L\", \"L'\", \"R\", \"R'\", \"F\", \"F'\", \"B\", \"B'\", \"U\", \"U'\", \"D\", \"D'\"]\n",
    "    \n",
    "    def apply_action(state, action):\n",
    "        \"\"\"Applies the action on the state and returns a new state.\n",
    "        Both `state` and returned state must be numpy array of 6 x 3 x 3 that represents a state of a Rubik's cube.\n",
    "        Action must be one of \"L\", \"L'\", \"R\", \"R'\", \"F\", \"F'\", \"B\", \"B'\", \"U\", \"U'\", \"D\", \"D'\".\n",
    "\n",
    "        First, deepcopy the initial state, and then call the respective functions that mutates the copied state.\n",
    "        Then, return the copied state.\n",
    "        \"\"\"\n",
    "\n",
    "        state = deepcopy(state)\n",
    "        match action:\n",
    "            case \"L\":\n",
    "                return Rubik.rotate_left_clockwise(state)\n",
    "            case \"L'\":\n",
    "                return Rubik.rotate_left_anticlockwise(state)\n",
    "            case \"R\":\n",
    "                return Rubik.rotate_right_clockwise(state)\n",
    "            case \"R'\":\n",
    "                return Rubik.rotate_right_anticlockwise(state)\n",
    "            case \"F\":\n",
    "                return Rubik.rotate_front_clockwise(state)\n",
    "            case \"F'\":\n",
    "                return Rubik.rotate_front_anticlockwise(state)\n",
    "            case \"B\":\n",
    "                return Rubik.rotate_back_clockwise(state)\n",
    "            case \"B'\":\n",
    "                return Rubik.rotate_back_anticlockwise(state)\n",
    "            case \"U\":\n",
    "                return Rubik.rotate_up_clockwise(state)\n",
    "            case \"U'\":\n",
    "                return Rubik.rotate_up_anticlockwise(state)\n",
    "            case \"D\":\n",
    "                return Rubik.rotate_down_clockwise(state)\n",
    "            case \"D'\":\n",
    "                return Rubik.rotate_down_anticlockwise(state)\n",
    "            case _:\n",
    "                raise ValueError(f\"Unrecognised action {action}\")\n",
    "\n",
    "    def rotate_face_clockwise(face):\n",
    "        temp_corner = face[0][0]\n",
    "        face[0][0] = face[2][0]\n",
    "        face[2][0] = face[2][2]\n",
    "        face[2][2] = face[0][2]\n",
    "        face[0][2] = temp_corner\n",
    "\n",
    "        temp_side = face[0][1]\n",
    "        face[0][1] = face[1][0]\n",
    "        face[1][0] = face[2][1]\n",
    "        face[2][1] = face[1][2]\n",
    "        face[1][2] = temp_side\n",
    "\n",
    "    def rotate_face_anticlockwise(face):\n",
    "        temp_corner = face[0][0]\n",
    "        face[0][0] = face[0][2]\n",
    "        face[0][2] = face[2][2]\n",
    "        face[2][2] = face[2][0]\n",
    "        face[2][0] = temp_corner\n",
    "\n",
    "        temp_side = face[0][1]\n",
    "        face[0][1] = face[1][2]\n",
    "        face[1][2] = face[2][1]\n",
    "        face[2][1] = face[1][0]\n",
    "        face[1][0] = temp_side\n",
    "\n",
    "    def rotate_left_clockwise(state):\n",
    "        temp1, temp2, temp3 = state[0, :, 0]\n",
    "        state[0, :, 0] = state[5, :, 0]\n",
    "        state[5, :, 0] = state[4, :, 0]\n",
    "        state[4, :, 0] = state[2, :, 0]\n",
    "        state[2, :, 0] = temp1, temp2, temp3\n",
    "        Rubik.rotate_face_clockwise(state[1])\n",
    "        return state\n",
    "\n",
    "    def rotate_left_anticlockwise(state):\n",
    "        temp1, temp2, temp3 = state[0, :, 0]\n",
    "        state[0, :, 0] = state[2, :, 0]\n",
    "        state[2, :, 0] = state[4, :, 0]\n",
    "        state[4, :, 0] = state[5, :, 0]\n",
    "        state[5, :, 0] = temp1, temp2, temp3\n",
    "        Rubik.rotate_face_anticlockwise(state[1])\n",
    "        return state\n",
    "\n",
    "    def rotate_right_clockwise(state):\n",
    "        temp1, temp2, temp3 = state[0, :, 2]\n",
    "        state[0, :, 2] = state[2, :, 2]\n",
    "        state[2, :, 2] = state[4, :, 2]\n",
    "        state[4, :, 2] = state[5, :, 2]\n",
    "        state[5, :, 2] = temp1, temp2, temp3\n",
    "        Rubik.rotate_face_clockwise(state[3])\n",
    "        return state\n",
    "\n",
    "    def rotate_right_anticlockwise(state):\n",
    "        temp1, temp2, temp3 = state[0, :, 2]\n",
    "        state[0, :, 2] = state[5, :, 2]\n",
    "        state[5, :, 2] = state[4, :, 2]\n",
    "        state[4, :, 2] = state[2, :, 2]\n",
    "        state[2, :, 2] = temp1, temp2, temp3\n",
    "        Rubik.rotate_face_anticlockwise(state[3])\n",
    "        return state\n",
    "\n",
    "    def rotate_front_clockwise(state):\n",
    "        temp1, temp2, temp3 = state[0, 2, :]\n",
    "        state[0, 2, :] = state[1, :, 2][::-1]\n",
    "        state[1, :, 2][::-1] = state[4, 0, :][::-1]\n",
    "        state[4, 0, :][::-1] = state[3, :, 0]\n",
    "        state[3, :, 0] = temp1, temp2, temp3\n",
    "        Rubik.rotate_face_clockwise(state[2])\n",
    "        return state\n",
    "\n",
    "    def rotate_front_anticlockwise(state):\n",
    "        temp1, temp2, temp3 = state[0, 2, :]\n",
    "        state[0, 2, :] = state[3, :, 0]\n",
    "        state[3, :, 0] = state[4, 0, :][::-1]\n",
    "        state[4, 0, :][::-1] = state[1, :, 2][::-1]\n",
    "        state[1, :, 2][::-1] = temp1, temp2, temp3\n",
    "        Rubik.rotate_face_anticlockwise(state[2])\n",
    "        return state\n",
    "\n",
    "    def rotate_back_clockwise(state):\n",
    "        temp1, temp2, temp3 = state[0, 0, :]\n",
    "        state[0, 0, :] = state[3, :, 2]\n",
    "        state[3, :, 2] = state[4, 2, :][::-1]\n",
    "        state[4, 2, :][::-1] = state[1, :, 0][::-1]\n",
    "        state[1, :, 0][::-1] = temp1, temp2, temp3\n",
    "        Rubik.rotate_face_clockwise(state[5])\n",
    "        return state\n",
    "\n",
    "    def rotate_back_anticlockwise(state):\n",
    "        temp1, temp2, temp3 = state[0, 0, :]\n",
    "        state[0, 0, :] = state[1, :, 0][::-1]\n",
    "        state[1, :, 0][::-1] = state[4, 2, :][::-1]\n",
    "        state[4, 2, :][::-1] = state[3, :, 2]\n",
    "        state[3, :, 2] = temp1, temp2, temp3\n",
    "        Rubik.rotate_face_anticlockwise(state[5])\n",
    "        return state\n",
    "\n",
    "    def rotate_up_clockwise(state):\n",
    "        temp1, temp2, temp3 = state[1, 0, :]\n",
    "        state[1, 0, :] = state[2, 0, :]\n",
    "        state[2, 0, :] = state[3, 0, :]\n",
    "        state[3, 0, :] = state[5, 2, :][::-1]\n",
    "        state[5, 2, :][::-1] = temp1, temp2, temp3\n",
    "        Rubik.rotate_face_clockwise(state[0])\n",
    "        return state\n",
    "\n",
    "    def rotate_up_anticlockwise(state):\n",
    "        temp1, temp2, temp3 = state[1, 0, :]\n",
    "        state[1, 0, :] = state[5, 2, :][::-1]\n",
    "        state[5, 2, :][::-1] = state[3, 0, :]\n",
    "        state[3, 0, :] = state[2, 0, :]\n",
    "        state[2, 0, :] = temp1, temp2, temp3\n",
    "        Rubik.rotate_face_anticlockwise(state[0])\n",
    "        return state\n",
    "\n",
    "    def rotate_down_clockwise(state):\n",
    "        temp1, temp2, temp3 = state[1, 2, :]\n",
    "        state[1, 2, :] = state[5, 0, :][::-1]\n",
    "        state[5, 0, :][::-1] = state[3, 2, :]\n",
    "        state[3, 2, :] = state[2, 2, :]\n",
    "        state[2, 2, :] = temp1, temp2, temp3\n",
    "        Rubik.rotate_face_clockwise(state[4])\n",
    "        return state\n",
    "\n",
    "    def rotate_down_anticlockwise(state):\n",
    "        temp1, temp2, temp3 = state[1, 2, :]\n",
    "        state[1, 2, :] = state[2, 2, :]\n",
    "        state[2, 2, :] = state[3, 2, :]\n",
    "        state[3, 2, :] = state[5, 0, :][::-1]\n",
    "        state[5, 0, :][::-1] = temp1, temp2, temp3\n",
    "        Rubik.rotate_face_anticlockwise(state[4])\n",
    "        return state\n",
    "\n",
    "    def turn_tuple(state):\n",
    "        return tuple(state.reshape(54))\n",
    "\n",
    "    def is_terminal(state):\n",
    "        centers = state[:, 1, 1]\n",
    "        return np.all(state == centers[:, None][:, None])\n",
    "\n",
    "    def turn_numpy(state):\n",
    "        return np.array(state).reshape((6, 3, 3))\n",
    "\n",
    "def heuristic(state, steps_taken):\n",
    "    def face_heuristic(face):\n",
    "        count = 0\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if i < 2 and face[i][j] == face[i + 1][j]:\n",
    "                    count += 1\n",
    "                if j < 2 and face[i][j] == face[i][j + 1]:\n",
    "                    count += 1\n",
    "        return count\n",
    "    return sum([face_heuristic(face) for face in state]) - 3.0 * steps_taken\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, state, steps_taken=0, parent=None, action=None):\n",
    "        \"\"\"Initialises a node.\n",
    "        `state`: A numpy array of dimension 6 x 3 x 3\n",
    "        `steps_taken`: The number of steps taken from the initial state.\n",
    "        `parent`: An instance of `Node` that contains the previous state.\n",
    "        `action`: The action that transitions the previous state to this state.\n",
    "        \"\"\"\n",
    "        self.state = Rubik.turn_tuple(state)\n",
    "        self.steps_taken = steps_taken\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.h_value = heuristic(state, steps_taken)\n",
    "\n",
    "    def __lt__(self, node):\n",
    "        \"\"\"Determines the priority of this node compared to another node.\n",
    "        This determines the position of this node in the search frontier.\n",
    "        \"\"\"\n",
    "        return self.h_value < node.h_value\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\"Determines the hash value of this node.\n",
    "        This enables the hashing algorithm of the set of explored states.\n",
    "        Nodes with the same states must have the same hash values.\n",
    "        \"\"\"\n",
    "        return hash(self.state)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"Determines the equality of two nodes.\n",
    "        This enables the hashing algorithm of the set of explored states.\n",
    "        Since we do not want to re-explore the same states, any two nodes\n",
    "        with the same state must be equal, regardless of the values of other fields.\n",
    "        \"\"\"\n",
    "        return self.state == other.state\n",
    "        \n",
    "    def get_numpy_state(self):\n",
    "        \"\"\"Get the numpy array that represents the state contained in this node.\n",
    "        The numpy array must be of dimension 6 x 3 x 3.\n",
    "        \"\"\"\n",
    "        return Rubik.turn_numpy(self.state)\n",
    "\n",
    "def reverse_move(move):\n",
    "    if len(move) == 2:\n",
    "        return move[0]\n",
    "    else:\n",
    "        return move + \"'\"\n",
    "\n",
    "def get_terminal_state():\n",
    "    return np.array([\n",
    "        [[i for k in range(3)] for j in range(3)] for i in range(1, 7)\n",
    "    ])\n",
    "\n",
    "def generate_puzzle(scramble):    \n",
    "    puzzle = get_terminal_state()\n",
    "    for action in scramble:\n",
    "        puzzle = Rubik.apply_action(puzzle, action)\n",
    "    scramble.reverse()\n",
    "    solution = [reverse_move(move) for move in scramble]\n",
    "    return puzzle, solution\n",
    "\n",
    "def solve(state, time_limit):\n",
    "    step_limit = 26\n",
    "    start_time = time()\n",
    "    first_node = Node(state)\n",
    "    frontier = SortedSet([first_node])\n",
    "    explored = {\n",
    "        first_node: first_node.steps_taken,\n",
    "    }\n",
    "\n",
    "    while len(frontier) != 0:\n",
    "        curr_node = frontier.pop()\n",
    "        curr_state = curr_node.get_numpy_state()\n",
    "        \n",
    "        for action in Rubik.actions:\n",
    "            child_state = Rubik.apply_action(curr_state, action)\n",
    "            if Rubik.is_terminal(child_state):\n",
    "                actions = [action]\n",
    "                while curr_node.parent is not None:\n",
    "                    actions.append(curr_node.action)\n",
    "                    curr_node = curr_node.parent\n",
    "                actions.reverse()\n",
    "                return actions, time() - start_time\n",
    "\n",
    "            if curr_node.steps_taken == step_limit - 1:\n",
    "                continue\n",
    "\n",
    "            child_node = Node(\n",
    "                child_state,\n",
    "                steps_taken=curr_node.steps_taken + 1,\n",
    "                parent=curr_node,\n",
    "                action=action,\n",
    "            )\n",
    "            if child_node in explored:\n",
    "                if explored[child_node] > child_node.steps_taken:\n",
    "                    explored[child_node] = child_node.steps_taken\n",
    "                    frontier.add(child_node)\n",
    "            else:\n",
    "                explored[child_node] = child_node.steps_taken\n",
    "                frontier.add(child_node)\n",
    "\n",
    "        if time() - start_time > time_limit:\n",
    "            return None, time_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de02ef5-6887-4264-a34d-fce5671bdd71",
   "metadata": {},
   "source": [
    "## Define the data generator\n",
    "\n",
    "The data generator would randomly generate a scramble, and generate the puzzle and the model solution for it.\n",
    "The puzzle would then go through the informed search to see if there is a more efficient solution.\n",
    "A few things to take note:\n",
    "1. The scramble generator must be such that it does not revert its previous action. This means, for each current move, we prevent the next move from being a reverse of it. There are many more ways that the next move can revert the current moves, but we can only go so far to prevent some of such cases.\n",
    "2. The final input generator would compare the solution returned by informed search and the model solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d288c5c-76fc-454d-bac9-d21a4a122951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scramble(num_of_moves):\n",
    "    scramble = []\n",
    "    current_reverse_move = None\n",
    "    for _ in range(num_of_moves):\n",
    "        move = random.choice(Rubik.actions)\n",
    "        while move == current_reverse_move:\n",
    "            move = random.choice(Rubik.actions)\n",
    "        current_reverse_move = reverse_move(move)\n",
    "        scramble.append(move)\n",
    "    return scramble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "087d2874-f425-4c46-ab3b-9cf3ebe7f28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U', \"F'\", \"B'\", \"U'\", 'D']\n",
      "[\"U'\", \"R'\", \"U'\", 'D', \"L'\", 'F', 'R', \"L'\", 'D', 'F']\n",
      "[\"B'\", \"R'\", 'F', 'R', 'B', 'L', 'R', \"B'\", 'L', \"F'\", \"D'\", 'R', \"D'\", 'L', 'F']\n"
     ]
    }
   ],
   "source": [
    "test_5_move_scramble = generate_scramble(5)\n",
    "test_10_move_scramble = generate_scramble(10)\n",
    "test_15_move_scramble = generate_scramble(15)\n",
    "\n",
    "print(test_5_move_scramble)\n",
    "print(test_10_move_scramble)\n",
    "print(test_15_move_scramble)\n",
    "\n",
    "assert all([move in Rubik.actions for move in test_5_move_scramble]) and len(test_5_move_scramble) == 5\n",
    "assert all([move in Rubik.actions for move in test_10_move_scramble]) and len(test_10_move_scramble) == 10\n",
    "assert all([move in Rubik.actions for move in test_15_move_scramble]) and len(test_15_move_scramble) == 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f4ecf5-a02a-4490-ba17-3e085d96dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input(num_of_moves, time_limit, debug=False):\n",
    "    scramble = generate_scramble(num_of_moves)\n",
    "    puzzle, model_solution = generate_puzzle(scramble)\n",
    "    if debug:\n",
    "        print(f\"Generating solution for {model_solution}\")\n",
    "    puzzle_tuple = Rubik.turn_tuple(puzzle)\n",
    "    \n",
    "    solution, time_spent = solve(puzzle, time_limit)\n",
    "    if debug:\n",
    "        print(f\"Solution found: {solution}, in {time_spent}\")\n",
    "    if solution is None:\n",
    "        return puzzle_tuple, model_solution[0]\n",
    "    elif len(solution) < len(model_solution):\n",
    "        return puzzle_tuple, solution[0]\n",
    "    else:\n",
    "        return puzzle_tuple, model_solution[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0176817-08ea-4816-bc2b-00dfe27fdd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating solution for ['D', \"B'\", 'R', 'U', 'U']\n",
      "Solution found: ['D', \"B'\", 'R', \"U'\", \"U'\"], in 0.008527994155883789\n",
      "((3, 3, 3, 0, 0, 5, 0, 0, 2, 5, 3, 3, 0, 1, 1, 2, 2, 0, 5, 5, 0, 2, 2, 0, 1, 3, 4, 1, 3, 2, 1, 3, 4, 5, 5, 2, 5, 2, 1, 4, 4, 1, 4, 4, 3, 1, 1, 0, 2, 5, 5, 4, 4, 4), 'D')\n",
      "Generating solution for ['U', 'B', 'B', 'F', \"L'\", \"F'\", 'B', \"F'\", 'R', \"L'\"]\n",
      "Solution found: ['U', \"B'\", 'F', \"B'\", \"L'\", 'B', \"F'\", \"F'\", 'R', \"L'\"], in 2.3437442779541016\n",
      "((0, 5, 1, 3, 0, 1, 3, 5, 1, 5, 4, 4, 0, 1, 4, 5, 3, 4, 5, 4, 2, 2, 2, 2, 1, 5, 2, 0, 0, 0, 0, 3, 1, 0, 3, 2, 2, 1, 3, 0, 4, 2, 1, 1, 4, 4, 4, 3, 5, 5, 2, 3, 3, 5), 'U')\n",
      "Generating solution for [\"F'\", 'B', 'L', \"R'\", 'F', 'L', 'B', \"L'\", 'R', 'R', \"F'\", 'B', 'B', 'L', \"R'\"]\n",
      "Solution found: None, in 5\n",
      "((3, 1, 2, 4, 0, 4, 4, 0, 1, 0, 1, 5, 0, 1, 4, 2, 3, 4, 3, 5, 5, 2, 2, 0, 2, 2, 1, 4, 3, 0, 1, 3, 1, 2, 4, 0, 3, 3, 4, 0, 4, 5, 0, 3, 5, 3, 5, 1, 2, 5, 5, 5, 2, 1), \"F'\")\n"
     ]
    }
   ],
   "source": [
    "test_time_limit = 5\n",
    "print(generate_input(5, test_time_limit, debug=True))\n",
    "print(generate_input(10, test_time_limit, debug=True))\n",
    "print(generate_input(15, test_time_limit, debug=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2159e3e8-6837-40bb-85eb-a6cdff345ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(initial_data={}, rounds=10, time_limit=5, debug=False):\n",
    "    action_map = { \"L\": 0, \"L'\": 1, \"R\": 2, \"R'\": 3, \"F\": 4, \"F'\": 5, \"B\": 6, \"B'\": 7, \"U\": 8, \"U'\": 9, \"D\": 10, \"D'\": 11 }\n",
    "    data = initial_data\n",
    "    for _ in range(rounds):\n",
    "        num_of_moves = random.randint(1, 32)\n",
    "        puzzle, action = generate_input(num_of_moves, time_limit=time_limit, debug=debug)\n",
    "        data[puzzle] = action_map[action]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "456c602f-ebf9-4435-b453-9ab568cab580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating solution for [\"D'\", \"D'\", 'F', 'R', 'U', 'D', 'R', \"L'\", \"B'\", \"U'\", \"B'\", \"L'\", \"D'\", 'F', \"R'\", 'B', 'D', 'D', \"L'\", 'U', 'B', \"F'\", 'L', \"B'\", 'F', 'D', 'B', \"R'\"]\n",
      "Solution found: None, in 5\n",
      "Generating solution for ['U', \"D'\", \"U'\", 'L', 'D', 'L', \"U'\", 'B', \"F'\", 'D', \"R'\", 'U', 'D', 'R', 'R', 'D', 'R', \"U'\", \"R'\", \"B'\", 'D', 'F', 'D', 'U', 'L', 'D', 'D', \"L'\", \"B'\", \"L'\"]\n",
      "Solution found: None, in 5\n",
      "Generating solution for ['L', 'D', 'B']\n",
      "Solution found: ['L', 'D', 'B'], in 0.0039522647857666016\n",
      "Generating solution for ['B', 'R', \"B'\", \"U'\", 'F', 'R', 'D', 'L', 'L', \"U'\", 'L', 'U', \"B'\", 'U', \"D'\"]\n",
      "Solution found: None, in 5\n",
      "Generating solution for [\"U'\", \"D'\", \"L'\", \"F'\", \"D'\", \"L'\", 'U', \"L'\", \"R'\", \"L'\", 'F', \"R'\", 'L', 'F']\n",
      "Solution found: None, in 5\n",
      "Generating solution for ['B', 'F', \"U'\", \"D'\", \"B'\", \"L'\", 'F', 'R', 'F', \"D'\", \"F'\", 'B', \"D'\", 'L', 'L', \"F'\", 'R', \"U'\", \"L'\", 'R', 'L', 'L', \"R'\", \"R'\", 'U', 'D']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m, in \u001b[0;36mgenerate_data\u001b[1;34m(initial_data, rounds, time_limit, debug)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rounds):\n\u001b[0;32m      5\u001b[0m     num_of_moves \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     puzzle, action \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_of_moves\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     data[puzzle] \u001b[38;5;241m=\u001b[39m action_map[action]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m, in \u001b[0;36mgenerate_input\u001b[1;34m(num_of_moves, time_limit, debug)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating solution for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_solution\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m puzzle_tuple \u001b[38;5;241m=\u001b[39m Rubik\u001b[38;5;241m.\u001b[39mturn_tuple(puzzle)\n\u001b[1;32m----> 8\u001b[0m solution, time_spent \u001b[38;5;241m=\u001b[39m \u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpuzzle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolution found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolution\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_spent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 274\u001b[0m, in \u001b[0;36msolve\u001b[1;34m(state, time_limit)\u001b[0m\n\u001b[0;32m    271\u001b[0m curr_state \u001b[38;5;241m=\u001b[39m curr_node\u001b[38;5;241m.\u001b[39mget_numpy_state()\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m Rubik\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 274\u001b[0m     child_state \u001b[38;5;241m=\u001b[39m \u001b[43mRubik\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Rubik\u001b[38;5;241m.\u001b[39mis_terminal(child_state):\n\u001b[0;32m    276\u001b[0m         actions \u001b[38;5;241m=\u001b[39m [action]\n",
      "Cell \u001b[1;32mIn[12], line 26\u001b[0m, in \u001b[0;36mRubik.apply_action\u001b[1;34m(state, action)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Rubik\u001b[38;5;241m.\u001b[39mrotate_right_anticlockwise(state)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRubik\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotate_front_clockwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Rubik\u001b[38;5;241m.\u001b[39mrotate_front_anticlockwise(state)\n",
      "Cell \u001b[1;32mIn[12], line 111\u001b[0m, in \u001b[0;36mRubik.rotate_front_clockwise\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m    109\u001b[0m state[\u001b[38;5;241m1\u001b[39m, :, \u001b[38;5;241m2\u001b[39m][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m0\u001b[39m, :][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    110\u001b[0m state[\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m0\u001b[39m, :][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;241m3\u001b[39m, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 111\u001b[0m \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m temp1, temp2, temp3\n\u001b[0;32m    112\u001b[0m Rubik\u001b[38;5;241m.\u001b[39mrotate_face_clockwise(state[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(generate_data(debug=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c65c47f-97ac-44d8-ad76-7871d067148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_main(filename=\"data/data.pkl\", rounds=10, time_limit=5, debug=True):\n",
    "    try:\n",
    "        with open(filename, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        data = {}\n",
    "\n",
    "    print(f\"Initial data size: {len(data)}\")\n",
    "    if debug:\n",
    "        print(f\"initial data: {data}\")\n",
    "\n",
    "    data = generate_data(initial_data=data, rounds=rounds, time_limit=time_limit, debug=debug)\n",
    "    print(f\"Final data size: {len(data)}\")\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f72e9ef-c039-4a5c-934f-aaed07288b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_data_main(rounds=5000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02865e0c-304f-4f58-8171-2567f4471881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1be35fa9-d040-473b-866c-cf35971a62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_no_informed_search(num_of_moves, debug=True):\n",
    "    scramble = generate_scramble(num_of_moves)\n",
    "    puzzle, model_solution = generate_puzzle(scramble)\n",
    "    puzzle_tuple = Rubik.turn_tuple(puzzle)\n",
    "\n",
    "    return puzzle_tuple, model_solution[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47aab4f6-cf9c-492c-86ee-90e582dbbed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_no_informed_search(initial_data={}, rounds=10, debug=True):\n",
    "    action_map = { \"L\": 0, \"L'\": 1, \"R\": 2, \"R'\": 3, \"F\": 4, \"F'\": 5, \"B\": 6, \"B'\": 7, \"U\": 8, \"U'\": 9, \"D\": 10, \"D'\": 11 }\n",
    "    data = initial_data\n",
    "    for i in range(rounds):\n",
    "        num_of_moves = random.randint(1, 26) # requires at most 26 moves to solve\n",
    "        puzzle, action = generate_input_no_informed_search(num_of_moves, debug)\n",
    "        data[puzzle] = (action_map[action], num_of_moves)\n",
    "        if debug and i % 10000 == 0:\n",
    "            print(f'{i} data points generated') \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1ee63bf-dabd-41c6-bad1-78b3e5500160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_no_informed_search_main(filename=\"data/data_no_informed_search.pkl\", rounds=10, debug=True):\n",
    "    try:\n",
    "        with open(filename, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        data = {}\n",
    "\n",
    "    print(f\"Initial data size: {len(data)}\")\n",
    "    if debug:\n",
    "        print(f\"initial data: {data}\")\n",
    "\n",
    "    data = generate_data_no_informed_search(initial_data=data, rounds=rounds, debug=debug)\n",
    "    print(f\"Final data size: {len(data)}\")\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29da5c40-af86-4de5-a170-3e3f10dddf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data size: 0\n",
      "initial data: {}\n",
      "0 data points generated\n",
      "10000 data points generated\n",
      "20000 data points generated\n",
      "30000 data points generated\n",
      "40000 data points generated\n",
      "50000 data points generated\n",
      "60000 data points generated\n",
      "70000 data points generated\n",
      "80000 data points generated\n",
      "90000 data points generated\n",
      "100000 data points generated\n",
      "110000 data points generated\n",
      "120000 data points generated\n",
      "130000 data points generated\n",
      "140000 data points generated\n",
      "150000 data points generated\n",
      "160000 data points generated\n",
      "170000 data points generated\n",
      "180000 data points generated\n",
      "190000 data points generated\n",
      "200000 data points generated\n",
      "210000 data points generated\n",
      "220000 data points generated\n",
      "230000 data points generated\n",
      "240000 data points generated\n",
      "250000 data points generated\n",
      "260000 data points generated\n",
      "270000 data points generated\n",
      "280000 data points generated\n",
      "290000 data points generated\n",
      "Final data size: 257664\n"
     ]
    }
   ],
   "source": [
    "generate_data_no_informed_search_main(rounds=300000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cc9b0f-f245-478a-91aa-8debc722987e",
   "metadata": {},
   "source": [
    "## The neural net\n",
    "\n",
    "We define the class representing the neural network. This class is to be trained on.\n",
    "\n",
    "The architecture has 3 layers, each with ReLU activation function:\n",
    "\n",
    "* 54 -> 512\n",
    "* 512 -> 128\n",
    "* 128 -> 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6edac939-c544-4d0e-aca2-d9eddb182528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetStep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(54, 4096),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(1024, 12),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc2ba5-6d64-4d16-9e4d-660a018c507f",
   "metadata": {},
   "source": [
    "## Load training data\n",
    "\n",
    "We load the training data from the generated file in the previous step. We then split them into train data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ba9615f-4729-486a-b26b-1362353444dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename=\"data/data.pkl\", test=0.2):\n",
    "    \"\"\"Loads training data from the indicated file, with a portion dedicated for test data\n",
    "    The returned value is a tuple of (x_train, y_train, x_test, y_test), each is a torch tensor.\n",
    "    \"\"\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f\"Data size: {len(data)}\")\n",
    "    \n",
    "    test_size = round(test * len(data))\n",
    "    train_size = len(data) - test_size\n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    for puzzle, move in data.items():\n",
    "        p = random.random()\n",
    "        if p < test_size / (test_size + train_size):\n",
    "            x_test.append(puzzle)\n",
    "            y_test.append(move)\n",
    "            test_size -= 1\n",
    "        else:\n",
    "            x_train.append(puzzle)\n",
    "            y_train.append(move)\n",
    "            train_size -= 1\n",
    "\n",
    "    return (\n",
    "        torch.tensor(x_train, dtype=torch.float),\n",
    "        torch.tensor(y_train, dtype=torch.long),\n",
    "        torch.tensor(x_test, dtype=torch.float),\n",
    "        torch.tensor(y_test, dtype=torch.long),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e09ec3b9-9756-4b2c-a349-5c42d8499385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 46108\n"
     ]
    }
   ],
   "source": [
    "test_x_train, test_y_train, test_x_test, test_y_test = load_data(test=0.2)\n",
    "with open(\"data/data.pkl\", \"rb\") as test_f:\n",
    "    test_data = pickle.load(test_f)\n",
    "expected_test_size = round(len(test_data) * 0.2)\n",
    "expected_train_size = len(test_data) - expected_test_size\n",
    "assert test_x_train.size() == torch.Size([expected_train_size, 54])\n",
    "assert test_y_train.size() == torch.Size([expected_train_size])\n",
    "assert test_x_test.size() == torch.Size([expected_test_size, 54])\n",
    "assert test_y_test.size() == torch.Size([expected_test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3afd35e-d355-43e3-85d0-0026c8799400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afe359fe-cf47-4a61-b100-c7ae7804ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_num_of_moves(filename=\"data/data_no_informed_search.pkl\", test=0.2):\n",
    "    \"\"\"Loads training data from the indicated file, with a portion dedicated for test data\n",
    "    The returned value is a tuple of (x_train, y_train, x_test, y_test, num_of_moves_test), each is a torch tensor.\n",
    "    \"\"\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f\"Data size: {len(data)}\")\n",
    "    \n",
    "    test_size = round(test * len(data))\n",
    "    train_size = len(data) - test_size\n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    num_of_moves_test = []\n",
    "    for puzzle, solution in data.items():\n",
    "        # solution is a (next_move, num_of_moves) tuple\n",
    "        p = random.random()\n",
    "        if p < test_size / (test_size + train_size):\n",
    "            x_test.append(puzzle)\n",
    "            y_test.append(solution[0])\n",
    "            num_of_moves_test.append(solution[1])\n",
    "            test_size -= 1\n",
    "        else:\n",
    "            x_train.append(puzzle)\n",
    "            y_train.append(solution[0])\n",
    "            train_size -= 1\n",
    "\n",
    "    return (\n",
    "        torch.tensor(x_train, dtype=torch.float),\n",
    "        torch.tensor(y_train, dtype=torch.long),\n",
    "        torch.tensor(x_test, dtype=torch.float),\n",
    "        torch.tensor(y_test, dtype=torch.long),\n",
    "        torch.tensor(num_of_moves_test)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa2e4455-92c1-4b05-88fd-3e24591b5933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 856967\n"
     ]
    }
   ],
   "source": [
    "test_x_train, test_y_train, test_x_test, test_y_test, test_num_of_moves_test = load_data_with_num_of_moves(test=0.2)\n",
    "with open(\"data/data_no_informed_search.pkl\", \"rb\") as test_f:\n",
    "    test_data = pickle.load(test_f)\n",
    "expected_test_size = round(len(test_data) * 0.2)\n",
    "expected_train_size = len(test_data) - expected_test_size\n",
    "assert test_x_train.size() == torch.Size([expected_train_size, 54])\n",
    "assert test_y_train.size() == torch.Size([expected_train_size])\n",
    "assert test_x_test.size() == torch.Size([expected_test_size, 54])\n",
    "assert test_y_test.size() == torch.Size([expected_test_size])\n",
    "assert test_num_of_moves_test.size() == torch.Size([expected_test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7711cacf-17f4-4b62-a92c-977024a1b1f9",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "\n",
    "We define a training loop that takes in two torch tensors,\n",
    "* `x_train`: The x_data torch tensor of size `(train_size, 54)`\n",
    "* `y_train`: The y_data torch tensor of size `(train_size)`\n",
    "* `epochs`: Number of training iterations\n",
    "\n",
    "The training loop then returns a neural network model that is trained on the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "760f6797-081b-4097-b858-f06080a1c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, initial_model=None, initial_optimiser=None, epochs=100, batch_size=-1):\n",
    "    model = initial_model if initial_model else NeuralNetStep()\n",
    "    optimiser = initial_optimiser if initial_optimiser else torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    if batch_size <= 0:\n",
    "        for i in range(epochs):\n",
    "            optimiser.zero_grad()\n",
    "            pred = model.forward(x_train)\n",
    "            loss = loss_fn(pred, y_train)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Completed epoch {i} with previous loss {loss}\")\n",
    "    else:\n",
    "        batch_n = 0\n",
    "        total_batch_num = math.ceil(len(x_train) / batch_size)\n",
    "        while batch_n < total_batch_num:\n",
    "            features = x_train[batch_n * batch_size : (batch_n + 1) * batch_size]\n",
    "            targets = y_train[batch_n * batch_size : (batch_n + 1) * batch_size]\n",
    "            \n",
    "            for i in range(epochs):        \n",
    "                optimiser.zero_grad()\n",
    "                pred = model.forward(features)\n",
    "                loss = loss_fn(pred, targets)\n",
    "                loss.backward()\n",
    "                optimiser.step()\n",
    "                if i == 0:\n",
    "                    print(f'Training batch {batch_n+1}/{total_batch_num}, initial loss of this batch is {loss}')\n",
    "            batch_n += 1\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "60eea42c-3f45-468e-a6a4-74c6dd02eb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 46108\n",
      "Completed epoch 0 with previous loss 2.489006519317627\n",
      "Completed epoch 10 with previous loss 2.4556515216827393\n",
      "Completed epoch 20 with previous loss 2.4311633110046387\n",
      "Completed epoch 30 with previous loss 2.4154109954833984\n",
      "Completed epoch 40 with previous loss 2.3957443237304688\n",
      "Completed epoch 50 with previous loss 2.3731448650360107\n",
      "Completed epoch 60 with previous loss 2.343139410018921\n",
      "Completed epoch 70 with previous loss 2.3102376461029053\n",
      "Completed epoch 80 with previous loss 2.2797844409942627\n",
      "Completed epoch 90 with previous loss 2.249770402908325\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = load_data()\n",
    "model = model\n",
    "#model = train_model(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ab72c57-f952-4782-8dd8-808718eef633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 257664\n",
      "Completed epoch 0 with previous loss 2.541945219039917\n",
      "Completed epoch 10 with previous loss 2.494835615158081\n",
      "Completed epoch 20 with previous loss 2.4463489055633545\n",
      "Completed epoch 30 with previous loss 2.4417881965637207\n",
      "Completed epoch 40 with previous loss 2.432758331298828\n",
      "Completed epoch 50 with previous loss 2.4268739223480225\n",
      "Completed epoch 60 with previous loss 2.420896530151367\n",
      "Completed epoch 70 with previous loss 2.414188861846924\n",
      "Completed epoch 80 with previous loss 2.4067935943603516\n",
      "Completed epoch 90 with previous loss 2.39858078956604\n"
     ]
    }
   ],
   "source": [
    "x_train_2, y_train_2, x_test_2, y_test_2, num_of_moves_test_2 = load_data_with_num_of_moves()\n",
    "#model_2 = train_model(x_train_2, y_train_2, epochs=300)\n",
    "model_2_alt = train_model(x_train_2, y_train_2, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9f5141-11b2-4b63-9fc5-52fc5c10cf1a",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "We evaluate the model using the test data, to determine if we need further training.\n",
    "\n",
    "The evaluate function takes in the following parameters:\n",
    "* `model`: The trained model\n",
    "* `x_test`: The test data\n",
    "* `y_test`: The test label\n",
    "\n",
    "The returned value is a float between `0` and `1` representing how accurate the model is.\n",
    "Value `0` means not accurate at all, and `1` means very accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68ee4009-e63e-4803-b980-ea48dc4f0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x_test, y_test):\n",
    "    output = model.forward(x_test)\n",
    "    predictions = torch.argmax(output, axis=1)\n",
    "    corrects = predictions == y_test\n",
    "    for i in range(12):\n",
    "        print(f\"Accuracy to predict move {i} is {torch.sum(y_test[corrects] == i) / torch.sum(y_test == i)}\")\n",
    "    \n",
    "    return (torch.sum(corrects) / y_test.shape[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "08c417da-7b70-449b-89cc-827a373761c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy to predict move 0 is 0.17965653538703918\n",
      "Accuracy to predict move 1 is 0.15961800515651703\n",
      "Accuracy to predict move 2 is 0.1260606050491333\n",
      "Accuracy to predict move 3 is 0.10443864017724991\n",
      "Accuracy to predict move 4 is 0.2882273197174072\n",
      "Accuracy to predict move 5 is 0.09919571131467819\n",
      "Accuracy to predict move 6 is 0.20420792698860168\n",
      "Accuracy to predict move 7 is 0.22884881496429443\n",
      "Accuracy to predict move 8 is 0.1595330685377121\n",
      "Accuracy to predict move 9 is 0.14606741070747375\n",
      "Accuracy to predict move 10 is 0.23882503807544708\n",
      "Accuracy to predict move 11 is 0.18005181849002838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17566688358783722"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94fe9903-45c4-4690-bbd7-ea7ffbf7e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_num_of_moves(model, x_test, y_test, num_of_moves_test):\n",
    "    output = model.forward(x_test)\n",
    "    predictions = torch.argmax(output, axis=1)\n",
    "    corrects = predictions == y_test\n",
    "    # for i in range(12):\n",
    "    #     print(f\"Accuracy to predict move {i} is {torch.sum(y_test[corrects] == i) / torch.sum(y_test == i)}\")\n",
    "    for num_of_moves in range(1, 27):\n",
    "        mask = num_of_moves_test_2 == num_of_moves\n",
    "        acc = torch.sum(predictions[mask] == y_test[mask]) / y_test[mask].shape[0]\n",
    "        print(f'Accuracy for puzzle with number of moves {num_of_moves} is {acc}')\n",
    "    \n",
    "    return (torch.sum(corrects) / y_test.shape[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d18038ff-8860-4a69-8005-9099c88d22bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for puzzle with number of moves 1 is 1.0\n",
      "Accuracy for puzzle with number of moves 2 is 0.8636363744735718\n",
      "Accuracy for puzzle with number of moves 3 is 0.8756219148635864\n",
      "Accuracy for puzzle with number of moves 4 is 0.7282700538635254\n",
      "Accuracy for puzzle with number of moves 5 is 0.6015543937683105\n",
      "Accuracy for puzzle with number of moves 6 is 0.48658648133277893\n",
      "Accuracy for puzzle with number of moves 7 is 0.3951111137866974\n",
      "Accuracy for puzzle with number of moves 8 is 0.32905226945877075\n",
      "Accuracy for puzzle with number of moves 9 is 0.2857760488986969\n",
      "Accuracy for puzzle with number of moves 10 is 0.2430117279291153\n",
      "Accuracy for puzzle with number of moves 11 is 0.21234354376792908\n",
      "Accuracy for puzzle with number of moves 12 is 0.19413763284683228\n",
      "Accuracy for puzzle with number of moves 13 is 0.16855822503566742\n",
      "Accuracy for puzzle with number of moves 14 is 0.15143488347530365\n",
      "Accuracy for puzzle with number of moves 15 is 0.13884082436561584\n",
      "Accuracy for puzzle with number of moves 16 is 0.13383062183856964\n",
      "Accuracy for puzzle with number of moves 17 is 0.11602451652288437\n",
      "Accuracy for puzzle with number of moves 18 is 0.09965187311172485\n",
      "Accuracy for puzzle with number of moves 19 is 0.10876265913248062\n",
      "Accuracy for puzzle with number of moves 20 is 0.09297250211238861\n",
      "Accuracy for puzzle with number of moves 21 is 0.0969800055027008\n",
      "Accuracy for puzzle with number of moves 22 is 0.10275150835514069\n",
      "Accuracy for puzzle with number of moves 23 is 0.08992650359869003\n",
      "Accuracy for puzzle with number of moves 24 is 0.09208261966705322\n",
      "Accuracy for puzzle with number of moves 25 is 0.09433962404727936\n",
      "Accuracy for puzzle with number of moves 26 is 0.08674804121255875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2074010819196701"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_with_num_of_moves(model_2, x_test_2, y_test_2, num_of_moves_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e3d01f-88a1-4893-b1f0-a55f48fc24ff",
   "metadata": {},
   "source": [
    "## Save data\n",
    "\n",
    "We now write the logic to save training data. This is done with the help of [this StackOverflow post](https://stackoverflow.com/questions/63655048/how-can-i-save-my-training-progress-in-pytorch-for-a-certain-batch-no)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de5996f8-8e17-47d4-98be-e90b4f9a8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimiser, save_path=\"data/model\"):\n",
    "    torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        #'optimiser': optimiser.state_dict(),\n",
    "    }, save_path)\n",
    "\n",
    "def load_checkpoint(load_path=\"data/model\"):\n",
    "    model = NeuralNetStep()\n",
    "    optimiser = torch.optim.Adam(model.parameters())\n",
    "    if not os.path.isfile(load_path):\n",
    "        return model, optimiser\n",
    "    \n",
    "    checkpoint = torch.load(load_path)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    #optimiser.load_state_dict(checkpoint['optimiser'])\n",
    "    return model, optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f9911b5-0d26-4280-a53f-f8bd796d403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(model_2, None, save_path=\"data/model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "144d9219-4f12-4875-92f9-c1355a56d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_main(epochs=1000):\n",
    "    \"\"\"Resume training model from saved data\n",
    "    The returned value is a tuple of `(model, accuracy)`,\n",
    "    where `model` is the trained model, and `accuracy` is the accuracy of the current model.\n",
    "    \"\"\"\n",
    "    x_train, y_train, x_test, y_test = load_data()\n",
    "    model, optimiser = load_checkpoint()\n",
    "    model = train_model(x_train, y_train, initial_model=model, initial_optimiser=optimiser, epochs=epochs)\n",
    "    save_checkpoint(model, optimiser)\n",
    "    accuracy = evaluate(model, x_test, y_test)\n",
    "    return model, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "000c3794-a5b2-4e3f-94e0-9b9834af5573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 17028\n",
      "Training loop 0\n",
      "Training loop 100\n",
      "Training loop 200\n",
      "Training loop 300\n",
      "Training loop 400\n",
      "Training loop 500\n",
      "Training loop 600\n",
      "Training loop 700\n",
      "Training loop 800\n",
      "Training loop 900\n",
      "Training loop 1000\n",
      "Training loop 1100\n",
      "Training loop 1200\n",
      "Training loop 1300\n",
      "Training loop 1400\n",
      "Training loop 1500\n",
      "Training loop 1600\n",
      "Training loop 1700\n",
      "Training loop 1800\n",
      "Training loop 1900\n",
      "Current accuracy: 0.3464474380016327\n"
     ]
    }
   ],
   "source": [
    "model, accuracy = train_model_main(epochs=2000)\n",
    "print(f\"Current accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a32b02-d797-425f-8220-86d67f1b6265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
